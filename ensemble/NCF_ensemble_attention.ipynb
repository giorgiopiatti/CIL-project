{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataset import extract_users_movies_ratings_lists\n",
    "import torch.nn as nn\n",
    "BASE_MODEL_FOLDER = '../results_ensemble'\n",
    "MODEL_LIST = [\n",
    "    #'AE_SWA',\n",
    "    'AE_SWA_ensemble_mean',\n",
    "    'ALS',\n",
    "    'NCF_dist_exp_2_embeddings_SWA',\n",
    "    'NCF_dist_exp_SWA',\n",
    "    'SVDpp_ensemble_gaussian'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetEnsembleResult(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset\n",
    "    x = (movie, user)\n",
    "    y = rating\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, users, movies, ratings_models, ratings=None) -> None:\n",
    "        super().__init__()\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings =ratings\n",
    "        self.ratings_models = ratings_models\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        user = self.users[index]\n",
    "        movie = self.movies[index]\n",
    "       \n",
    "        rating_models = self.ratings_models[index]\n",
    "       \n",
    "        if self.ratings is None:\n",
    "            return user, movie, rating_models\n",
    "        \n",
    "        rating = self.ratings[index]\n",
    "        return user, movie, rating_models, rating\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_train(split):\n",
    "    users = None \n",
    "    movies = None\n",
    "    models_ratings = []\n",
    "    for m in MODEL_LIST:\n",
    "        df = pd.read_csv(f'{BASE_MODEL_FOLDER}/{m}/{m}_split_{split}_val_results.csv')\n",
    "        users, movies, ratings = extract_users_movies_ratings_lists(df)\n",
    "        models_ratings.append(ratings)\n",
    "\n",
    "\n",
    "    df_val = pd.read_csv(f'../data_val_train_kfold/partition_{split}_val.csv')\n",
    "    _, _, y = extract_users_movies_ratings_lists(df_val)\n",
    "\n",
    "    d_train = DatasetEnsembleResult(users, movies, np.column_stack(models_ratings), y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(d_train, batch_size=32, drop_last=False, shuffle=True)\n",
    "    return train_dataloader\n",
    "\n",
    "def get_dataset_test():\n",
    "    users = None \n",
    "    movies = None\n",
    "    models_ratings = []\n",
    "    for m in MODEL_LIST:\n",
    "        df = pd.read_csv(f'{BASE_MODEL_FOLDER}/{m}/{m}_final_results.csv')\n",
    "        users, movies, ratings = extract_users_movies_ratings_lists(df)\n",
    "        models_ratings.append(ratings)\n",
    "\n",
    "    d_train = DatasetEnsembleResult(users, movies, np.column_stack(models_ratings))\n",
    "    train_dataloader = torch.utils.data.DataLoader(d_train, batch_size=32, drop_last=False, shuffle=True)\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataloader = get_dataset_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_users, number_of_movies = (10000, 1000)\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, emb_size=3):\n",
    "        super().__init__()\n",
    "        self.users_embeddings = nn.Embedding(number_of_users, embedding_dim=emb_size)\n",
    "        self.movies_embeddings = nn.Embedding(number_of_movies, embedding_dim=emb_size)\n",
    "\n",
    "        self.ncf = nn.Sequential(\n",
    "            nn.Linear(emb_size*2, len(MODEL_LIST)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(len(MODEL_LIST),  len(MODEL_LIST)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, users, movies, models_ratings):\n",
    "        u = self.users_embeddings(users)\n",
    "        m = self.movies_embeddings(movies)\n",
    "\n",
    "        concat = torch.cat([u, m], dim=1)\n",
    "        coeff = self.ncf(concat)\n",
    "\n",
    "        coeff= coeff + 1e-6\n",
    "        coeff = coeff / coeff.sum(dim=1).unsqueeze(-1)\n",
    "        \n",
    "        out = torch.mul(models_ratings, coeff)\n",
    "        out = out.sum(dim=1)\n",
    "       \n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        users, movies, models_ratings, y = batch\n",
    "        yhat = self.forward(users, movies, models_ratings)\n",
    "\n",
    "        loss = torch.sqrt(torch.mean((yhat-y)**2))\n",
    "        self.log('train_loss', loss, on_epoch=True, on_step=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        users, movies, models_ratings= batch\n",
    "        yhat = self.forward(users, movies, models_ratings)\n",
    "        return yhat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(split):\n",
    "    train_dataloader = get_dataset_train(split)\n",
    "    model = Model()\n",
    "    trainer = pl.Trainer(max_epochs=2)\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader)\n",
    "\n",
    "    pred = trainer.predict(model, dataloaders=test_dataloader)\n",
    "    yhat = torch.concat(pred)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(0,5):\n",
    "    yhat = run(i)\n",
    "    acc.append(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176952,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.column_stack(acc).mean(axis=1)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import save_predictions\n",
    "save_predictions('NCF_ensemble_attention.csv', res)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
