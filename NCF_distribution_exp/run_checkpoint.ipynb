{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro import param\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from neptune.new.types import File\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dataset import extract_users_movies_ratings_lists, TripletDataset, save_predictions\n",
    "\n",
    "#Useful constants\n",
    "number_of_users, number_of_movies = (10000, 1000)\n",
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 256\n",
    "DATA_DIR = '../data'\n",
    "\n",
    "#Data source and split into val and train\n",
    "data_pd = pd.read_csv(DATA_DIR+'/data_train.csv')\n",
    "train_pd, val_pd = train_test_split(data_pd, train_size=0.9, random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "users_train, movies_train, ratings_train = extract_users_movies_ratings_lists(train_pd)\n",
    "d_train = TripletDataset(users_train, movies_train, ratings_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(d_train, batch_size=BATCH_SIZE, drop_last=True, shuffle=True)\n",
    "\n",
    "users_val, movies_val, ratings_val = extract_users_movies_ratings_lists(val_pd)\n",
    "d_val= TripletDataset(users_val, movies_val, ratings_val)\n",
    "val_dataloader = torch.utils.data.DataLoader(d_val, batch_size=BATCH_SIZE, drop_last=False, shuffle=False)\n",
    "\n",
    "\n",
    "test_pd = pd.read_csv(DATA_DIR+'/sampleSubmission.csv')\n",
    "users_test, movies_test, ratings_test = extract_users_movies_ratings_lists(test_pd)\n",
    "d_test= TripletDataset(users_test, movies_test, ratings_test, is_test_dataset=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(d_test, batch_size=BATCH_SIZE, drop_last=False, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = 'NCF_dist_exp'\n",
    "DEBUG = False\n",
    "\n",
    "proxies = {\n",
    "'http': 'http://proxy.ethz.ch:3128',\n",
    "'https': 'http://proxy.ethz.ch:3128',\n",
    "}\n",
    "neptune_logger = NeptuneLogger(\n",
    "    project=\"TiCinesi/CIL-project\", \n",
    "    api_key='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmMzQyZmQ3MS02OGM5LTQ2Y2EtOTEzNC03MjBjMzUyN2UzNDMifQ==',\n",
    "    mode = 'debug' if DEBUG else 'async',\n",
    "    name=EXPERIMENT_NAME,\n",
    "    tags=[],  # optional\n",
    "    proxies=proxies\n",
    ")\n",
    "\n",
    "from model import NCFDistribution\n",
    "\n",
    "params =  {\n",
    "    'embedding_size': 39, 'hidden_size': 14, \n",
    "    'alpha': 0.1812479548064849, \n",
    "    'sigma_prior': 0.2286523513862455, \n",
    "    'distance_0_to_3': 0.33728622361587846, \n",
    "    'distance_3_to_2': 0.986891143302744, \n",
    "    'distance_2_to_1': 0.6932965943259499, \n",
    "    'distance_0_to_4': 0.9201001618073893, \n",
    "    'distance_4_to_5': 1.4031427821242537, \n",
    "    'p_dropout': 0.18573958557776177, \n",
    "    'scaling': 2.687106607498346\n",
    "}\n",
    "model = NCFDistribution.load_from_checkpoint('./epoch=19-step=82740.ckpt', **params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "        max_epochs=20, \n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else None,\n",
    "        devices=1, \n",
    "        log_every_n_steps=1, \n",
    "        detect_anomaly=True, \n",
    "        track_grad_norm=2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /home/gio/kDrive/ETH/ETH_code/CIL-project/models/NCF_distribution_exp/lightning_logs\n",
      "/home/gio/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 4598/4598 [00:42<00:00, 107.55it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(res_path, predictions):\n",
    "    test_pd = pd.read_csv(DATA_DIR+'/sampleSubmission.csv')\n",
    "   \n",
    "    test_pd = test_pd.astype({'Prediction': 'float'})\n",
    "\n",
    "    test_pd.iloc[:, 1] = predictions\n",
    "\n",
    " \n",
    "    test_pd.to_csv(res_path, index=False, float_format='%.3f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/TiCinesi/CIL-project/e/CIL1-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info (NVML): NVML Shared Library Not Found. GPU usage metrics may not be reported. For more information, see https://docs.neptune.ai/you-should-know/what-can-you-log-and-display#hardware-consumption\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "#trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "\n",
    "#predictions = trainer.predict(model, dataloaders=test_dataloader)\n",
    "\n",
    "yhat = torch.concat(predictions)\n",
    "\n",
    "save_predictions(f'{EXPERIMENT_NAME}-predictedSubmission.csv', yhat)\n",
    "neptune_logger.experiment['results/end_model'].upload(File(f'{EXPERIMENT_NAME}-predictedSubmission.csv'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
